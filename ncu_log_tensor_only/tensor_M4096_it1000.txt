M=4096, N=4096, K=4096, tensor_iters=1000
==PROF== Connected to process 2944409 (/home/ivy/custom_workloads/git_repo/tensor_core_only)
==PROF== Profiling "wmma_gemm_kernel" - 0: 0%..
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
..50%....100% - 9 passes
==PROF== Profiling "wmma_gemm_kernel" - 1: 0%....50%....100% - 9 passes
Tensor Core WMMA GEMM: 4096x4096x4096 tensor_iters=1000 time=214387.766 ms
Sample C[mid,mid]=8588638.000000
==PROF== Disconnected from process 2944409
[2944409] tensor_core_only@127.0.0.1
  wmma_gemm_kernel(const __half *, const __half *, float *, int, int, int, int) (256, 256, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -----------------
    Metric Name               Metric Unit      Metric Value
    ----------------------- ------------- -----------------
    DRAM Frequency          cycle/nsecond              9,24
    SM Frequency            cycle/nsecond              1,36
    Elapsed Cycles                  cycle    32 274 802 716
    Memory Throughput                   %             41,59
    DRAM Throughput                     %             38,29
    Duration                       second             23,65
    L1/TEX Cache Throughput             %             41,46
    L2 Cache Throughput                 %             35,76
    SM Active Cycles                cycle 32 379 408 917,51
    Compute (SM) Throughput             %             10,40
    ----------------------- ------------- -----------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 65 536
    Registers Per Thread             register/thread              40
    Shared Memory Configuration Size           Kbyte           16,38
    Driver Shared Memory Per Block       Kbyte/block            1,02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       2 097 152
    Waves Per SM                                               51,20
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           48
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           48
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %        33,33
    Achieved Occupancy                        %        33,11
    Achieved Active Warps Per SM           warp        15,89
    ------------------------------- ----------- ------------

    OPT   This kernel's theoretical occupancy (33.3%) is limited by the number of blocks that can fit on the SM. This   
          kernel's theoretical occupancy (33.3%) is limited by the required amount of shared memory. See the CUDA Best  
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

