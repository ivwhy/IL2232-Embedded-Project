==PROF== Connected to process 3354280 (/home/ivy/custom_workloads/git_repo/src_cuda/bin_cuda/tensor_core_only)
==PROF== Profiling "wmma_gemm_kernel" - 0: 0%..
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
..50%....100% - 9 passes
==PROF== Profiling "wmma_gemm_kernel" - 1: 0%....50%....100% - 9 passes
Tensor Core WMMA GEMM: M=16384 tensor_iters=5 time=68283.281 ms
Sample C[mid,mid]=178689.953125
==PROF== Disconnected from process 3354280
[3354280] tensor_core_only@127.0.0.1
  wmma_gemm_kernel(const __half *, const __half *, float *, int, int, int, int) (1024, 1024, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -----------------
    Metric Name               Metric Unit      Metric Value
    ----------------------- ------------- -----------------
    DRAM Frequency          cycle/nsecond              9,26
    SM Frequency            cycle/nsecond              1,37
    Elapsed Cycles                  cycle    10 361 111 198
    Memory Throughput                   %             43,23
    DRAM Throughput                     %             43,23
    Duration                       second              7,58
    L1/TEX Cache Throughput             %             41,68
    L2 Cache Throughput                 %             30,42
    SM Active Cycles                cycle 10 306 027 453,41
    Compute (SM) Throughput             %             10,37
    ----------------------- ------------- -----------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                              1 048 576
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           16,38
    Driver Shared Memory Per Block       Kbyte/block            1,02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread      33 554 432
    Waves Per SM                                              819,20
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           48
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %        33,33
    Achieved Occupancy                        %        33,40
    Achieved Active Warps Per SM           warp        16,03
    ------------------------------- ----------- ------------

    OPT   This kernel's theoretical occupancy (33.3%) is limited by the number of blocks that can fit on the SM. This   
          kernel's theoretical occupancy (33.3%) is limited by the required amount of shared memory. See the CUDA Best  
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

  wmma_gemm_kernel(const __half *, const __half *, float *, int, int, int, int) (1024, 1024, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -----------------
    Metric Name               Metric Unit      Metric Value
    ----------------------- ------------- -----------------
    DRAM Frequency          cycle/nsecond              9,20
    SM Frequency            cycle/nsecond              1,36
    Elapsed Cycles                  cycle    10 290 193 407
    Memory Throughput                   %             43,52
    DRAM Throughput                     %             43,52
    Duration                       second              7,57
    L1/TEX Cache Throughput             %             41,61
    L2 Cache Throughput                 %             30,54
    SM Active Cycles                cycle 10 324 120 352,10
    Compute (SM) Throughput             %             10,44
    ----------------------- ------------- -----------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                              1 048 576
    Registers Per Thread             register/thread              32
    Shared Memory Configuration Size           Kbyte           16,38
    Driver Shared Memory Per Block       Kbyte/block            1,02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread      33 554 432
    Waves Per SM                                              819,20
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           48
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %        33,33
    Achieved Occupancy                        %        33,42
    Achieved Active Warps Per SM           warp        16,04
    ------------------------------- ----------- ------------

    OPT   This kernel's theoretical occupancy (33.3%) is limited by the number of blocks that can fit on the SM. This   
          kernel's theoretical occupancy (33.3%) is limited by the required amount of shared memory. See the CUDA Best  
          Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more      
          details on optimizing occupancy.                                                                              

